{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 3, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 61, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Asus/Desktop/daddy-ai-main/src/lib/fileStore.ts"],"sourcesContent":["import { randomUUID } from \"crypto\";\n\nexport interface FileEntry {\n  buffer: Buffer;\n  filename: string;\n  mimeType: string;\n  uploadedAt: number;\n}\n\nconst store = new Map<string, FileEntry>();\n\nconst TTL_MS = 30 * 60 * 1000; // 30 minutes\n\nfunction cleanup() {\n  const now = Date.now();\n  for (const [id, entry] of store) {\n    if (now - entry.uploadedAt > TTL_MS) {\n      store.delete(id);\n    }\n  }\n}\n\nexport function saveFile(buffer: Buffer, filename: string, mimeType: string): string {\n  cleanup();\n  const id = randomUUID();\n  store.set(id, { buffer, filename, mimeType, uploadedAt: Date.now() });\n  console.log(`Saved file: ${id}, filename: ${filename}, store size: ${store.size}`);\n  return id;\n}\n\nexport function getFile(fileId: string): FileEntry | undefined {\n  cleanup();\n  const file = store.get(fileId);\n  console.log(`Getting file: ${fileId}, found: ${file ? 'yes' : 'no'}`);\n  if (file) {\n    console.log(`File details: ${file.filename}, ${file.mimeType}, ${file.buffer.length} bytes`);\n  }\n  return file;\n}\n\nexport function deleteFile(fileId: string): void {\n  store.delete(fileId);\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;;AASA,MAAM,QAAQ,IAAI;AAElB,MAAM,SAAS,KAAK,KAAK,MAAM,aAAa;AAE5C,SAAS;IACP,MAAM,MAAM,KAAK,GAAG;IACpB,KAAK,MAAM,CAAC,IAAI,MAAM,IAAI,MAAO;QAC/B,IAAI,MAAM,MAAM,UAAU,GAAG,QAAQ;YACnC,MAAM,MAAM,CAAC;QACf;IACF;AACF;AAEO,SAAS,SAAS,MAAc,EAAE,QAAgB,EAAE,QAAgB;IACzE;IACA,MAAM,KAAK,IAAA,mHAAU;IACrB,MAAM,GAAG,CAAC,IAAI;QAAE;QAAQ;QAAU;QAAU,YAAY,KAAK,GAAG;IAAG;IACnE,QAAQ,GAAG,CAAC,CAAC,YAAY,EAAE,GAAG,YAAY,EAAE,SAAS,cAAc,EAAE,MAAM,IAAI,EAAE;IACjF,OAAO;AACT;AAEO,SAAS,QAAQ,MAAc;IACpC;IACA,MAAM,OAAO,MAAM,GAAG,CAAC;IACvB,QAAQ,GAAG,CAAC,CAAC,cAAc,EAAE,OAAO,SAAS,EAAE,OAAO,QAAQ,MAAM;IACpE,IAAI,MAAM;QACR,QAAQ,GAAG,CAAC,CAAC,cAAc,EAAE,KAAK,QAAQ,CAAC,EAAE,EAAE,KAAK,QAAQ,CAAC,EAAE,EAAE,KAAK,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC;IAC7F;IACA,OAAO;AACT;AAEO,SAAS,WAAW,MAAc;IACvC,MAAM,MAAM,CAAC;AACf","debugId":null}},
    {"offset": {"line": 109, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Asus/Desktop/daddy-ai-main/src/app/api/parse/route.ts"],"sourcesContent":["/* eslint-disable @typescript-eslint/no-explicit-any */\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { getFile } from \"@/lib/fileStore\";\n\nexport const runtime = \"nodejs\";\n\n// Simple regex-based resume parser\nfunction parseResumeText(text: string) {\n  // Basic structure with fallbacks\n  const result: any = {\n    name: \"\",\n    contact: {},\n    summary: \"\",\n    skills: [],\n    experience: [],\n    education: [],\n  };\n\n  // Try to extract name (first line that looks like a name)\n  const lines = text\n    .split(\"\\n\")\n    .map((line) => line.trim())\n    .filter((line) => line.length > 0);\n  if (lines.length > 0) {\n    // Simple heuristic: assume the first non-empty line is the name\n    result.name = lines[0];\n  }\n\n  // Extract email\n  const emailMatch = text.match(\n    /\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b/\n  );\n  if (emailMatch) {\n    result.contact.email = emailMatch[0];\n  }\n\n  // Extract phone (simple pattern)\n  const phoneMatch = text.match(\n    /\\b(\\+\\d{1,2}\\s?)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b/\n  );\n  if (phoneMatch) {\n    result.contact.phone = phoneMatch[0];\n  }\n\n  // Try to find sections using common headings\n  const sections = {\n    experience: [\"experience\", \"work experience\", \"employment\", \"work history\"],\n    education: [\"education\", \"academic\", \"qualifications\"],\n    skills: [\"skills\", \"technical skills\", \"competencies\", \"technologies\"],\n    summary: [\"summary\", \"objective\", \"profile\"],\n  };\n\n  // Extract section content\n  Object.entries(sections).forEach(([section, keywords]) => {\n    const lowerText = text.toLowerCase();\n\n    for (const keyword of keywords) {\n      const index = lowerText.indexOf(keyword);\n      if (index !== -1) {\n        // Find the content after the section heading\n        const afterHeading = text.substring(index + keyword.length);\n        const nextSectionIndex = Math.min(\n          ...Object.values(sections)\n            .flat()\n            .map((k) => afterHeading.toLowerCase().indexOf(k))\n            .filter((i) => i > 0)\n        );\n\n        if (nextSectionIndex > 0) {\n          result[section] = afterHeading.substring(0, nextSectionIndex).trim();\n        } else {\n          result[section] = afterHeading.trim();\n        }\n        break;\n      }\n    }\n  });\n\n  // Try to parse experience into array of objects\n  if (typeof result.experience === \"string\") {\n    // Simple parsing: split by likely job entries\n    const experienceEntries = result.experience.split(\n      /(?=\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\b|\\d{4})/\n    );\n\n    result.experience = experienceEntries\n      .filter((entry: { trim: () => { (): any; new(): any; length: number; }; }) => entry.trim().length > 0)\n      .map((entry: string) => {\n        // Try to extract title, company, and bullets\n        const lines = entry\n          .split(\"\\n\")\n          .filter((line) => line.trim().length > 0);\n\n        if (lines.length === 0) return null;\n\n        const experienceItem: any = {\n          title: \"\",\n          company: \"\",\n          bullets: [],\n        };\n\n        // First line might contain title and company\n        const firstLine = lines[0];\n        const titleCompanyMatch =\n          firstLine.match(/(.*?)\\s+at\\s+(.*)/i) ||\n          firstLine.match(/(.*?),\\s*(.*)/);\n\n        if (titleCompanyMatch) {\n          experienceItem.title = titleCompanyMatch[1].trim();\n          experienceItem.company = titleCompanyMatch[2].trim();\n        } else {\n          experienceItem.title = firstLine.trim();\n        }\n\n        // Remaining lines as bullets\n        if (lines.length > 1) {\n          experienceItem.bullets = lines\n            .slice(1)\n            .filter((line) => line.trim().length > 0)\n            .map((line) => line.replace(/^[-•*]\\s*/, \"\").trim());\n        }\n\n        return experienceItem;\n      })\n      .filter((item: null) => item !== null);\n  }\n\n  // Parse skills into array\n  if (typeof result.skills === \"string\") {\n    result.skills = result.skills\n      .split(/[,;•\\-]|\\n/)\n      .map((skill: string) => skill.trim())\n      .filter((skill: string) => skill.length > 0);\n  }\n\n  return result;\n}\n\nexport async function POST(req: NextRequest) {\n  try {\n    let body;\n    try {\n      body = await req.json();\n    } catch (parseError) {\n      return NextResponse.json(\n        { success: false, error: `Invalid JSON in request body  Error ${parseError}` },\n        { status: 400 }\n      );\n    }\n    const { fileId } = body;\n\n    if (!fileId) {\n      return NextResponse.json(\n        { success: false, error: \"No fileId provided\" },\n        { status: 400 }\n      );\n    }\n\n    const file = getFile(fileId);\n    if (!file) {\n      return NextResponse.json(\n        { success: false, error: \"File not found\" },\n        { status: 404 }\n      );\n    }\n\n    let rawText = \"\";\n    if (file.mimeType.includes(\"pdf\") || file.filename.endsWith(\".pdf\")) {\n      // Use pdf2json\n      const PDFParser = (await import(\"pdf2json\")).default;\n      const pdfParser = new PDFParser();\n\n      rawText = await new Promise((resolve, reject) => {\n        let text = \"\";\n\n        // eslint-disable-next-line @typescript-eslint/no-unused-vars\n        pdfParser.on(\"pdfParser_dataError\", (_errData: any) => {\n          reject(new Error(\"Failed to parse PDF\"));\n        });\n\n        pdfParser.on(\"pdfParser_dataReady\", (pdfData: any) => {\n          try {\n            text = pdfData.Pages.map((page: any) =>\n              page.Texts.map((textObj: any) =>\n                decodeURIComponent(textObj.R[0].T)\n              ).join(\" \")\n            ).join(\"\\n\");\n\n            resolve(text);\n          } catch (e) {\n            reject(e);\n          }\n        });\n\n        pdfParser.parseBuffer(file.buffer);\n      });\n    } else if (\n      file.mimeType.includes(\"officedocument.wordprocessingml.document\") ||\n      file.filename.endsWith(\".docx\")\n    ) {\n      const mammoth = (await import(\"mammoth\")).default;\n      const { value } = await mammoth.extractRawText({ buffer: file.buffer });\n      rawText = value;\n    } else {\n      rawText = file.buffer.toString(\"utf8\");\n    }\n\n    // Parse the raw text into structured data\n    const structuredData = parseResumeText(rawText);\n\n    return NextResponse.json({\n      success: true,\n      parsed: {\n        rawText,\n        structured: structuredData,\n      },\n    });\n  } catch (err: any) {\n    console.error(\"Parse error:\", err);\n    return NextResponse.json(\n      { success: false, error: err.message || \"Parse failed\" },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":"AAAA,qDAAqD;;;;;;AACrD;AACA;;;AAEO,MAAM,UAAU;AAEvB,mCAAmC;AACnC,SAAS,gBAAgB,IAAY;IACnC,iCAAiC;IACjC,MAAM,SAAc;QAClB,MAAM;QACN,SAAS,CAAC;QACV,SAAS;QACT,QAAQ,EAAE;QACV,YAAY,EAAE;QACd,WAAW,EAAE;IACf;IAEA,0DAA0D;IAC1D,MAAM,QAAQ,KACX,KAAK,CAAC,MACN,GAAG,CAAC,CAAC,OAAS,KAAK,IAAI,IACvB,MAAM,CAAC,CAAC,OAAS,KAAK,MAAM,GAAG;IAClC,IAAI,MAAM,MAAM,GAAG,GAAG;QACpB,gEAAgE;QAChE,OAAO,IAAI,GAAG,KAAK,CAAC,EAAE;IACxB;IAEA,gBAAgB;IAChB,MAAM,aAAa,KAAK,KAAK,CAC3B;IAEF,IAAI,YAAY;QACd,OAAO,OAAO,CAAC,KAAK,GAAG,UAAU,CAAC,EAAE;IACtC;IAEA,iCAAiC;IACjC,MAAM,aAAa,KAAK,KAAK,CAC3B;IAEF,IAAI,YAAY;QACd,OAAO,OAAO,CAAC,KAAK,GAAG,UAAU,CAAC,EAAE;IACtC;IAEA,6CAA6C;IAC7C,MAAM,WAAW;QACf,YAAY;YAAC;YAAc;YAAmB;YAAc;SAAe;QAC3E,WAAW;YAAC;YAAa;YAAY;SAAiB;QACtD,QAAQ;YAAC;YAAU;YAAoB;YAAgB;SAAe;QACtE,SAAS;YAAC;YAAW;YAAa;SAAU;IAC9C;IAEA,0BAA0B;IAC1B,OAAO,OAAO,CAAC,UAAU,OAAO,CAAC,CAAC,CAAC,SAAS,SAAS;QACnD,MAAM,YAAY,KAAK,WAAW;QAElC,KAAK,MAAM,WAAW,SAAU;YAC9B,MAAM,QAAQ,UAAU,OAAO,CAAC;YAChC,IAAI,UAAU,CAAC,GAAG;gBAChB,6CAA6C;gBAC7C,MAAM,eAAe,KAAK,SAAS,CAAC,QAAQ,QAAQ,MAAM;gBAC1D,MAAM,mBAAmB,KAAK,GAAG,IAC5B,OAAO,MAAM,CAAC,UACd,IAAI,GACJ,GAAG,CAAC,CAAC,IAAM,aAAa,WAAW,GAAG,OAAO,CAAC,IAC9C,MAAM,CAAC,CAAC,IAAM,IAAI;gBAGvB,IAAI,mBAAmB,GAAG;oBACxB,MAAM,CAAC,QAAQ,GAAG,aAAa,SAAS,CAAC,GAAG,kBAAkB,IAAI;gBACpE,OAAO;oBACL,MAAM,CAAC,QAAQ,GAAG,aAAa,IAAI;gBACrC;gBACA;YACF;QACF;IACF;IAEA,gDAAgD;IAChD,IAAI,OAAO,OAAO,UAAU,KAAK,UAAU;QACzC,8CAA8C;QAC9C,MAAM,oBAAoB,OAAO,UAAU,CAAC,KAAK,CAC/C;QAGF,OAAO,UAAU,GAAG,kBACjB,MAAM,CAAC,CAAC,QAAqE,MAAM,IAAI,GAAG,MAAM,GAAG,GACnG,GAAG,CAAC,CAAC;YACJ,6CAA6C;YAC7C,MAAM,QAAQ,MACX,KAAK,CAAC,MACN,MAAM,CAAC,CAAC,OAAS,KAAK,IAAI,GAAG,MAAM,GAAG;YAEzC,IAAI,MAAM,MAAM,KAAK,GAAG,OAAO;YAE/B,MAAM,iBAAsB;gBAC1B,OAAO;gBACP,SAAS;gBACT,SAAS,EAAE;YACb;YAEA,6CAA6C;YAC7C,MAAM,YAAY,KAAK,CAAC,EAAE;YAC1B,MAAM,oBACJ,UAAU,KAAK,CAAC,yBAChB,UAAU,KAAK,CAAC;YAElB,IAAI,mBAAmB;gBACrB,eAAe,KAAK,GAAG,iBAAiB,CAAC,EAAE,CAAC,IAAI;gBAChD,eAAe,OAAO,GAAG,iBAAiB,CAAC,EAAE,CAAC,IAAI;YACpD,OAAO;gBACL,eAAe,KAAK,GAAG,UAAU,IAAI;YACvC;YAEA,6BAA6B;YAC7B,IAAI,MAAM,MAAM,GAAG,GAAG;gBACpB,eAAe,OAAO,GAAG,MACtB,KAAK,CAAC,GACN,MAAM,CAAC,CAAC,OAAS,KAAK,IAAI,GAAG,MAAM,GAAG,GACtC,GAAG,CAAC,CAAC,OAAS,KAAK,OAAO,CAAC,aAAa,IAAI,IAAI;YACrD;YAEA,OAAO;QACT,GACC,MAAM,CAAC,CAAC,OAAe,SAAS;IACrC;IAEA,0BAA0B;IAC1B,IAAI,OAAO,OAAO,MAAM,KAAK,UAAU;QACrC,OAAO,MAAM,GAAG,OAAO,MAAM,CAC1B,KAAK,CAAC,cACN,GAAG,CAAC,CAAC,QAAkB,MAAM,IAAI,IACjC,MAAM,CAAC,CAAC,QAAkB,MAAM,MAAM,GAAG;IAC9C;IAEA,OAAO;AACT;AAEO,eAAe,KAAK,GAAgB;IACzC,IAAI;QACF,IAAI;QACJ,IAAI;YACF,OAAO,MAAM,IAAI,IAAI;QACvB,EAAE,OAAO,YAAY;YACnB,OAAO,kLAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO,CAAC,oCAAoC,EAAE,YAAY;YAAC,GAC7E;gBAAE,QAAQ;YAAI;QAElB;QACA,MAAM,EAAE,MAAM,EAAE,GAAG;QAEnB,IAAI,CAAC,QAAQ;YACX,OAAO,kLAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAqB,GAC9C;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,OAAO,IAAA,sKAAO,EAAC;QACrB,IAAI,CAAC,MAAM;YACT,OAAO,kLAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAiB,GAC1C;gBAAE,QAAQ;YAAI;QAElB;QAEA,IAAI,UAAU;QACd,IAAI,KAAK,QAAQ,CAAC,QAAQ,CAAC,UAAU,KAAK,QAAQ,CAAC,QAAQ,CAAC,SAAS;YACnE,eAAe;YACf,MAAM,YAAY,CAAC,+IAAwB,EAAE,OAAO;YACpD,MAAM,YAAY,IAAI;YAEtB,UAAU,MAAM,IAAI,QAAQ,CAAC,SAAS;gBACpC,IAAI,OAAO;gBAEX,6DAA6D;gBAC7D,UAAU,EAAE,CAAC,uBAAuB,CAAC;oBACnC,OAAO,IAAI,MAAM;gBACnB;gBAEA,UAAU,EAAE,CAAC,uBAAuB,CAAC;oBACnC,IAAI;wBACF,OAAO,QAAQ,KAAK,CAAC,GAAG,CAAC,CAAC,OACxB,KAAK,KAAK,CAAC,GAAG,CAAC,CAAC,UACd,mBAAmB,QAAQ,CAAC,CAAC,EAAE,CAAC,CAAC,GACjC,IAAI,CAAC,MACP,IAAI,CAAC;wBAEP,QAAQ;oBACV,EAAE,OAAO,GAAG;wBACV,OAAO;oBACT;gBACF;gBAEA,UAAU,WAAW,CAAC,KAAK,MAAM;YACnC;QACF,OAAO,IACL,KAAK,QAAQ,CAAC,QAAQ,CAAC,+CACvB,KAAK,QAAQ,CAAC,QAAQ,CAAC,UACvB;YACA,MAAM,UAAU,CAAC,yIAAuB,EAAE,OAAO;YACjD,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,QAAQ,cAAc,CAAC;gBAAE,QAAQ,KAAK,MAAM;YAAC;YACrE,UAAU;QACZ,OAAO;YACL,UAAU,KAAK,MAAM,CAAC,QAAQ,CAAC;QACjC;QAEA,0CAA0C;QAC1C,MAAM,iBAAiB,gBAAgB;QAEvC,OAAO,kLAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,QAAQ;gBACN;gBACA,YAAY;YACd;QACF;IACF,EAAE,OAAO,KAAU;QACjB,QAAQ,KAAK,CAAC,gBAAgB;QAC9B,OAAO,kLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO,IAAI,OAAO,IAAI;QAAe,GACvD;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}